"""
–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pymorphy3
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ Telegram-–±–æ—Ç–∞
"""
import logging
import re
from typing import Set, Optional
from pymorphy3 import MorphAnalyzer

logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
try:
    morph = MorphAnalyzer()
    MORPH_AVAILABLE = True
except Exception as e:
    logger.error(f"Failed to initialize MorphAnalyzer: {e}")
    morph = None
    MORPH_AVAILABLE = False

def extract_words_from_text(text: str) -> Set[str]:
    """
    –ò–∑–≤–ª–µ—á—å –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—Å–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è —Å–∏—Å—Ç–µ–º—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        
    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    """
    if not text or not MORPH_AVAILABLE:
        return set()
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
    clean_text = re.sub(r'[^\w\s]', ' ', text.lower())
    words = clean_text.split()
    
    normalized_words = set()
    for word in words:
        if len(word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            normalized = normalize_word(word)
            if normalized:
                normalized_words.add(normalized)
    
    return normalized_words

def normalize_word(word: str) -> Optional[str]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–ª–æ–≤–æ (–ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ) –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    
    Args:
        word: –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
        
    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not word or not MORPH_AVAILABLE:
        return word
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    parsed = morph.parse(word)
    if parsed:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é (–Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—É—é) –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
        normal_form = parsed[0].normal_form
        return normal_form.lower()
    return word.lower()

# –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∞–≤–∏–ª–æ —Å–∫–ª–æ–Ω–µ–Ω–∏—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–ª—è –ø—Å–µ–≤–¥–æ–Ω–∏–º–æ–≤
ADJECTIVE_DECLENSION = {
    # –ú—É–∂—Å–∫–æ–π —Ä–æ–¥ -> –ñ–µ–Ω—Å–∫–∏–π —Ä–æ–¥
    "—ã–π": "–∞—è",
    "–∏–π": "—è—è", 
    "–æ–π": "–∞—è",
}

def decline_adjective_simple(adjective: str, gender: str = "femn") -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–µ —Å–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ —Ä–æ–¥—É (–¥–ª—è –ø—Å–µ–≤–¥–æ–Ω–∏–º–æ–≤)
    
    Args:
        adjective: –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –≤ –º—É–∂—Å–∫–æ–º —Ä–æ–¥–µ
        gender: –†–æ–¥ ("masc", "femn")
        
    Returns:
        –°–∫–ª–æ–Ω–µ–Ω–Ω–æ–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ
    """
    if not adjective or gender == "masc":
        return adjective
    
    # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∞–≤–∏–ª–æ: –∑–∞–º–µ–Ω—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ
    for masc_ending, femn_ending in ADJECTIVE_DECLENSION.items():
        if adjective.endswith(masc_ending):
            return adjective[:-len(masc_ending)] + femn_ending
    
    return adjective

def get_noun_gender_simple(noun: str) -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–¥–∞ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ (–¥–ª—è –ø—Å–µ–≤–¥–æ–Ω–∏–º–æ–≤)
    
    Args:
        noun: –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
        
    Returns:
        –†–æ–¥ ("masc", "femn")
    """
    if not noun:
        return "femn"
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –º—É–∂—Å–∫–∏—Ö —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö (–∏—Å–∫–ª—é—á–µ–Ω–∏—è)
    masculine_nouns = ["–º–µ–¥–≤–µ–¥—å", "–∫–æ–Ω—å", "–¥–µ–Ω—å", "–ø–µ–Ω—å", "–æ–ª–µ–Ω—å", "–ª–æ—Å—å", "–∫–æ–Ω—å"]
    if noun in masculine_nouns:
        return "masc"
    
    # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–æ–¥–∞
    feminine_endings = ["–∞", "—è"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–µ–Ω—Å–∫–∏–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    for ending in feminine_endings:
        if noun.endswith(ending):
            return "femn"
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –º—É–∂—Å–∫–æ–π —Ä–æ–¥
    return "masc"

def process_alias_morphology_simple(alias: str) -> str:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—é –ø—Å–µ–≤–¥–æ–Ω–∏–º–∞ (—Å–∫–ª–æ–Ω–∏—Ç—å –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ —Ä–æ–¥—É —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ)
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ pymorphy3 –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
    
    Args:
        alias: –ü—Å–µ–≤–¥–æ–Ω–∏–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ "—ç–º–æ–¥–∑–∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ"
        
    Returns:
        –ü—Å–µ–≤–¥–æ–Ω–∏–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–∫–ª–æ–Ω–µ–Ω–Ω—ã–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–º
    """
    if not alias:
        return alias
    
    # –†–∞–∑–±–∏—Ä–∞–µ–º –ø—Å–µ–≤–¥–æ–Ω–∏–º –Ω–∞ —á–∞—Å—Ç–∏
    parts = alias.split()
    if len(parts) < 3:
        return alias
    
    emoji, adjective, noun = parts[0], parts[1], parts[2]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–¥ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ
    gender = get_noun_gender_simple(noun)
    
    # –°–∫–ª–æ–Ω—è–µ–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ
    declined_adjective = decline_adjective_simple(adjective, gender)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result_parts = [emoji, declined_adjective, noun]
    if len(parts) > 3:
        result_parts.extend(parts[3:])
    
    return " ".join(result_parts)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_morphology():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π"""
    test_cases = [
        "üêµ —Ä–æ–≥–æ–≤–æ–æ–±–º–∞–Ω–∫–æ–≤—ã–π –æ–±–µ–∑—å—è–Ω–∞",
        "üê± –≥—É—Ç—Ç–∞–ø–µ—Ä—á–µ–≤—ã–π –∫–æ—Ç",
        "üê∂ —Å—É—Ä–≥—É—á–Ω—ã–π –ø–µ—Å",
        "ü¶ä –≤–∏—Ä–∏–¥–∏–∞–Ω–æ–≤—ã–π –ª–∏—Å–∞"
    ]
    
    print("Testing morphology processing:")
    for test_case in test_cases:
        result = process_alias_morphology_simple(test_case)
        print(f"  '{test_case}' -> '{result}'")

if __name__ == "__main__":
    test_morphology()
